{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sciencebasepy\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading https://www.sciencebase.gov/catalog/file/get/5d67eacae4b0c4f70cf15be3?f=__disk__94%2F45%2F0d%2F94450ddf141d1ece357b061d0266a6d2d3979aab to data/stinson2019/raw/ACERnet_LatLon.csv\n",
      "downloading https://www.sciencebase.gov/catalog/file/get/5d67eacae4b0c4f70cf15be3?f=__disk__fe%2Fc4%2F82%2Ffec482696f3df4b364e8ddc03ae29b7ad3bfc09e to data/stinson2019/raw/ACERnet_sap_2012_2017_ID.csv\n",
      "downloading https://www.sciencebase.gov/catalog/file/get/5d67eacae4b0c4f70cf15be3?f=__disk__59%2Ffc%2F64%2F59fc6442687fa582d9f9f5e8b57963c47b9192c7 to data/stinson2019/raw/Sap Quantity_6_29_19.xml\n"
     ]
    }
   ],
   "source": [
    "# Downloads all files from ScienceBase item number \"5d67eacae4b0c4f70cf15be3\"\n",
    "\n",
    "## Data website ##\n",
    "# https://www.sciencebase.gov/catalog/item/5d67eacae4b0c4f70cf15be3\n",
    "\n",
    "## Citation ##\n",
    "# Stinson, K., Rapp, J., Ahmed, S., Lutz, D., Huish, R., Dufour, B., and Morelli, T.L., 2019,\n",
    "# Sap Quantity at Study Sites in the Northeast: U.S. Geological Survey data release, https://doi.org/10.5066/P9H65YCC.\n",
    "\n",
    "\n",
    "sb = sciencebasepy.SbSession()\n",
    "\n",
    "if not os.path.exists(\"../data/stinson2019/raw\"):\n",
    "    os.makedirs(\"../data/stinson2019/raw\")\n",
    "\n",
    "item_json = sb.get_item(\"5d67eacae4b0c4f70cf15be3\")\n",
    "sb.get_item_files(item_json, \"../data/stinson2019/raw\")\n",
    "\n",
    "# Convert data csv files to dataframes and pickle\n",
    "df = pd.read_csv('../data/stinson2019/raw/ACERnet_sap_2012_2017_ID.csv',\n",
    "                parse_dates=['Date', 'Year'])\n",
    "df.columns=[x.lower().replace('.','_') for x in list(df.columns)]\n",
    "df.to_pickle('../data/stinson2019/stinson2019_df')\n",
    "\n",
    "locations = pd.read_csv('../data/stinson2019/raw/ACERnet_LatLon.csv')\n",
    "locations.to_pickle('../data/stinson2019/stinson2019_locations')\n",
    "\n",
    "del df, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads data from study listed below and creates pandas dataframes containing the data.  Dataframes are saved to .csv.\n",
    "\n",
    "## Data website ##\n",
    "# https://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-hfr.338.1\n",
    "\n",
    "## Citation ##\n",
    "# Templer, P. 2020. Sap Flow in Red Maple and Red Oak in the Harvard Forest Snow Removal Study 2011 ver 1. \n",
    "# Environmental Data Initiative. https://doi.org/10.6073/pasta/f4e8ef6675dff989baae075b476e9f13 (Accessed 2021-01-04).\n",
    "\n",
    "### Code below has been adapted from: 'https://portal.edirepository.org/nis/codeGeneration?packageId=knb-lter-hfr.338.1&statisticalFileType=py'\n",
    "\n",
    "# Package ID: knb-lter-hfr.338.1 Cataloging System:https://pasta.edirepository.org.\n",
    "# Data set title: Sap Flow in Red Maple and Red Oak in the Harvard Forest Snow Removal Study 2011.\n",
    "# Data set creator:  Pamela Templer -  \n",
    "# Contact:  Information Manager -  Harvard Forest  - hf-im@lists.fas.harvard.edu\n",
    "# Stylesheet v1.0 for metadata conversion into program: John H. Porter, Univ. Virginia, jporter@virginia.edu      \n",
    "# \n",
    "# This program creates numbered PANDA dataframes named dt1,dt2,dt3...,\n",
    "# one for each data table in the dataset. It also provides some basic\n",
    "# summaries of their contents. NumPy and Pandas modules need to be installed\n",
    "# for the program to run. \n",
    "\n",
    "infile1  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/338/1/a34fde7eee187f323b8d0eea1dc74823\".strip() \n",
    "infile1  = infile1.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt1 =pd.read_csv(infile1 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"datetime\",     \n",
    "                    \"doy\",     \n",
    "                    \"year\",     \n",
    "                    \"time\",     \n",
    "                    \"plott\",     \n",
    "                    \"treatment\",     \n",
    "                    \"tree\",     \n",
    "                    \"species\",     \n",
    "                    \"instant_sap\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'datetime',\n",
    "                        'year',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'datetime':[\n",
    "                          'NA',],\n",
    "                  'doy':[\n",
    "                          'NA',],\n",
    "                  'year':[\n",
    "                          'NA',],\n",
    "                  'time':[\n",
    "                          'NA',],\n",
    "                  'plot':[\n",
    "                          'NA',],\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'species':[\n",
    "                          'NA',],\n",
    "                  'instant_sap':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt1=dt1.assign(datetime_datetime=pd.to_datetime(dt1.datetime,errors='coerce')) \n",
    "dt1.doy=pd.to_numeric(dt1.doy,errors='coerce',downcast='integer') \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt1=dt1.assign(year_datetime=pd.to_datetime(dt1.year,errors='coerce')) \n",
    "dt1.time=pd.to_numeric(dt1.time,errors='coerce',downcast='integer')  \n",
    "dt1.plott=dt1.plott.astype('category')  \n",
    "dt1.treatment=dt1.treatment.astype('category')  \n",
    "dt1.tree=dt1.tree.astype('category')  \n",
    "dt1.species=dt1.species.astype('category') \n",
    "dt1.instant_sap=pd.to_numeric(dt1.instant_sap,errors='coerce') \n",
    "      \n",
    "if not os.path.exists('../data/templer2020/raw'):\n",
    "    os.makedirs('../data/templer2020/raw')\n",
    "    \n",
    "dt1.to_pickle('../data/templer2020/templer2020_df')\n",
    "del dt1\n",
    "\n",
    "\n",
    "# Download raw data and save as csv\n",
    "raw_data = requests.get(infile1)\n",
    "\n",
    "with open('../data/templer2020/raw/templer2020_raw1.csv', 'wb+') as data_file:\n",
    "     for chunk in raw_data:\n",
    "            data_file.write(chunk)\n",
    "\n",
    "# Download metadata and save\n",
    "metadata_url = 'https://pasta.lternet.edu/package/metadata/eml/knb-lter-hfr/338/1'\n",
    "metadata_xml = requests.get(metadata_url)\n",
    "\n",
    "with open('../data/templer2020/raw/templer2020_metadata.xml', 'w+') as metadata_file:\n",
    "     metadata_file.write(metadata_xml.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads data from study listed below and creates pandas dataframes containing the data.  Dataframes are saved to .csv.\n",
    "\n",
    "## Data website ##\n",
    "# https://portal.edirepository.org/nis/mapbrowse?packageid=knb-lter-hfr.285.3\n",
    "\n",
    "## Citation ##\n",
    "# Rapp, J., E. Crone, and K. Stinson. 2020. Maple Reproduction and Sap Flow at Harvard Forest since 2011 ver 3. Environmental Data Initiative. \n",
    "# https://doi.org/10.6073/pasta/3b8b9a83188b910bb3d27d3be59bdd4e (Accessed 2021-01-04).\n",
    "\n",
    "### Code below has been adapted from: 'https://portal.edirepository.org/nis/codeGeneration?packageId=knb-lter-hfr.285.3&statisticalFileType=py'\n",
    "\n",
    "# Package ID: knb-lter-hfr.285.3 Cataloging System:https://pasta.edirepository.org.\n",
    "# Data set title: Maple Reproduction and Sap Flow at Harvard Forest since 2011.\n",
    "# Data set creator:  Joshua Rapp -  \n",
    "# Data set creator:  Elizabeth Crone -  \n",
    "# Data set creator:  Kristina Stinson -  \n",
    "# Contact:  Joshua Rapp -  Harvard Forest  - rapp@fas.harvard.edu\n",
    "# Stylesheet v1.0 for metadata conversion into program: John H. Porter, Univ. Virginia, jporter@virginia.edu      \n",
    "# \n",
    "# This program creates numbered PANDA dataframes named dt1,dt2,dt3...,\n",
    "# one for each data table in the dataset. It also provides some basic\n",
    "# summaries of their contents. NumPy and Pandas modules need to be installed\n",
    "# for the program to run. \n",
    "\n",
    "\n",
    "infile1  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/70673164176668f2f0450115e59f31bd\".strip() \n",
    "infile1  = infile1.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt1 =pd.read_csv(infile1 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"date\",     \n",
    "                    \"tree\",     \n",
    "                    \"tap\",     \n",
    "                    \"species\",     \n",
    "                    \"dbh\",     \n",
    "                    \"tap_bearing\",     \n",
    "                    \"tap_height\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'date',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'date':[\n",
    "                          'NA',],\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'tap':[\n",
    "                          'NA',],\n",
    "                  'species':[\n",
    "                          'NA',],\n",
    "                  'dbh':[\n",
    "                          'NA',],\n",
    "                  'tap_bearing':[\n",
    "                          'NA',],\n",
    "                  'tap_height':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt1=dt1.assign(date_datetime=pd.to_datetime(dt1.date,errors='coerce'))  \n",
    "dt1.tree=dt1.tree.astype('category')  \n",
    "dt1.tap=dt1.tap.astype('category')  \n",
    "dt1.species=dt1.species.astype('category') \n",
    "dt1.dbh=pd.to_numeric(dt1.dbh,errors='coerce') \n",
    "dt1.tap_bearing=pd.to_numeric(dt1.tap_bearing,errors='coerce',downcast='integer') \n",
    "dt1.tap_height=pd.to_numeric(dt1.tap_height,errors='coerce',downcast='integer') \n",
    "      \n",
    "infile2  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/c1f4585bebbf0c76d32352d254bc8e64\".strip() \n",
    "infile2  = infile2.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt2 =pd.read_csv(infile2 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"date\",     \n",
    "                    \"tree\",     \n",
    "                    \"tap\",     \n",
    "                    \"time\",     \n",
    "                    \"datetime\",     \n",
    "                    \"sugar\",     \n",
    "                    \"species\",     \n",
    "                    \"sap_wt\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'date',\n",
    "                        'time',\n",
    "                        'datetime',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'date':[\n",
    "                          'NA',],\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'tap':[\n",
    "                          'NA',],\n",
    "                  'time':[\n",
    "                          'NA',],\n",
    "                  'datetime':[\n",
    "                          'NA',],\n",
    "                  'sugar':[\n",
    "                          'NA',],\n",
    "                  'species':[\n",
    "                          'NA',],\n",
    "                  'sap_wt':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt2=dt2.assign(date_datetime=pd.to_datetime(dt2.date,errors='coerce'))  \n",
    "dt2.tree=dt2.tree.astype('category')  \n",
    "dt2.tap=dt2.tap.astype('category') \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt2=dt2.assign(time_datetime=pd.to_datetime(dt2.time,errors='coerce')) \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt2=dt2.assign(datetime_datetime=pd.to_datetime(dt2.datetime,errors='coerce')) \n",
    "dt2.sugar=pd.to_numeric(dt2.sugar,errors='coerce')  \n",
    "dt2.species=dt2.species.astype('category') \n",
    "dt2.sap_wt=pd.to_numeric(dt2.sap_wt,errors='coerce') \n",
    "      \n",
    "      \n",
    "infile3  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/316c7943e741a678ecfd8495e24ec55a\".strip() \n",
    "infile3  = infile3.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt3 =pd.read_csv(infile3 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"year\",     \n",
    "                    \"tree_num\",     \n",
    "                    \"first_sex\",     \n",
    "                    \"flowering_intensity\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'year',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'year':[\n",
    "                          'NA',],\n",
    "                  'tree_num':[\n",
    "                          'NA',],\n",
    "                  'first_sex':[\n",
    "                          'NA',],\n",
    "                  'flowering_intensity':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt3=dt3.assign(year_datetime=pd.to_datetime(dt3.year,errors='coerce'))  \n",
    "dt3.tree_num=dt3.tree_num.astype('category')  \n",
    "dt3.first_sex=dt3.first_sex.astype('category')  \n",
    "dt3.flowering_intensity=dt3.flowering_intensity.astype('category') \n",
    "      \n",
    "\n",
    "infile4  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/46badf5c80db2c78d2ecb5370747ca95\".strip() \n",
    "infile4  = infile4.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt4 =pd.read_csv(infile4 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"date\",     \n",
    "                    \"tree\",     \n",
    "                    \"branch\",     \n",
    "                    \"canopy_strata\",     \n",
    "                    \"internode_year\",     \n",
    "                    \"internode_num\",     \n",
    "                    \"bud_num\",     \n",
    "                    \"bud_pos\",     \n",
    "                    \"num_male\",     \n",
    "                    \"num_female\",     \n",
    "                    \"num_unknown\",     \n",
    "                    \"leaves\",     \n",
    "                    \"num_leaves\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'date',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'date':[\n",
    "                          'NA',],\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'branch':[\n",
    "                          'NA',],\n",
    "                  'canopy_strata':[\n",
    "                          'NA',],\n",
    "                  'internode_year':[\n",
    "                          'NA',],\n",
    "                  'internode_num':[\n",
    "                          'NA',],\n",
    "                  'bud_num':[\n",
    "                          'NA',],\n",
    "                  'bud_pos':[\n",
    "                          'NA',],\n",
    "                  'num_male':[\n",
    "                          'NA',],\n",
    "                  'num_female':[\n",
    "                          'NA',],\n",
    "                  'num_unknown':[\n",
    "                          'NA',],\n",
    "                  'leaves':[\n",
    "                          'NA',],\n",
    "                  'num_leaves':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt4=dt4.assign(date_datetime=pd.to_datetime(dt4.date,errors='coerce'))  \n",
    "dt4.tree=dt4.tree.astype('category')  \n",
    "dt4.branch=dt4.branch.astype('category')  \n",
    "dt4.canopy_strata=dt4.canopy_strata.astype('category') \n",
    "dt4.internode_year=pd.to_numeric(dt4.internode_year,errors='coerce',downcast='integer')  \n",
    "dt4.internode_num=dt4.internode_num.astype('category')  \n",
    "dt4.bud_num=dt4.bud_num.astype('category')  \n",
    "dt4.bud_pos=dt4.bud_pos.astype('category') \n",
    "dt4.num_male=pd.to_numeric(dt4.num_male,errors='coerce',downcast='integer') \n",
    "dt4.num_female=pd.to_numeric(dt4.num_female,errors='coerce',downcast='integer') \n",
    "dt4.num_unknown=pd.to_numeric(dt4.num_unknown,errors='coerce',downcast='integer')  \n",
    "dt4.leaves=dt4.leaves.astype('category') \n",
    "dt4.num_leaves=pd.to_numeric(dt4.num_leaves,errors='coerce',downcast='integer') \n",
    "      \n",
    "\n",
    "infile5  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/150309317a285c00cd44058f65701af7\".strip() \n",
    "infile5  = infile5.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt5 =pd.read_csv(infile5 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"year\",     \n",
    "                    \"tree\",     \n",
    "                    \"branch\",     \n",
    "                    \"internode_year\",     \n",
    "                    \"internode_num\",     \n",
    "                    \"internode_length\",     \n",
    "                    \"num_buds\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'year',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'year':[\n",
    "                          'NA',],\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'branch':[\n",
    "                          'NA',],\n",
    "                  'internode_year':[\n",
    "                          'NA',],\n",
    "                  'internode_num':[\n",
    "                          'NA',],\n",
    "                  'internode_length':[\n",
    "                          'NA',],\n",
    "                  'num_buds':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt5=dt5.assign(year_datetime=pd.to_datetime(dt5.year,errors='coerce'))  \n",
    "dt5.tree=dt5.tree.astype('category')  \n",
    "dt5.branch=dt5.branch.astype('category') \n",
    "dt5.internode_year=pd.to_numeric(dt5.internode_year,errors='coerce',downcast='integer')  \n",
    "dt5.internode_num=dt5.internode_num.astype('category') \n",
    "dt5.internode_length=pd.to_numeric(dt5.internode_length,errors='coerce') \n",
    "dt5.num_buds=pd.to_numeric(dt5.num_buds,errors='coerce',downcast='integer') \n",
    "\n",
    "infile6  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/1ccb7c40e71c99f0746d6c51207530dc\".strip() \n",
    "infile6  = infile6.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt6 =pd.read_csv(infile6 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"date\",     \n",
    "                    \"tree\",     \n",
    "                    \"branch\",     \n",
    "                    \"treatment\",     \n",
    "                    \"internode_year\",     \n",
    "                    \"internode_num\",     \n",
    "                    \"internode_length\",     \n",
    "                    \"leaves\",     \n",
    "                    \"leaves_missing\",     \n",
    "                    \"leaf_area\",     \n",
    "                    \"num_samaras\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'date',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'date':[\n",
    "                          'NA',],\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'branch':[\n",
    "                          'NA',],\n",
    "                  'treatment':[\n",
    "                          'NA',],\n",
    "                  'internode_year':[\n",
    "                          'NA',],\n",
    "                  'internode_num':[\n",
    "                          'NA',],\n",
    "                  'internode_length':[\n",
    "                          'NA',],\n",
    "                  'leaves':[\n",
    "                          'NA',],\n",
    "                  'leaves_missing':[\n",
    "                          'NA',],\n",
    "                  'leaf_area':[\n",
    "                          'NA',],\n",
    "                  'num_samaras':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt6=dt6.assign(date_datetime=pd.to_datetime(dt6.date,errors='coerce'))  \n",
    "dt6.tree=dt6.tree.astype('category')  \n",
    "dt6.branch=dt6.branch.astype('category')  \n",
    "dt6.treatment=dt6.treatment.astype('category') \n",
    "dt6.internode_year=pd.to_numeric(dt6.internode_year,errors='coerce',downcast='integer')  \n",
    "dt6.internode_num=dt6.internode_num.astype('category') \n",
    "dt6.internode_length=pd.to_numeric(dt6.internode_length,errors='coerce',downcast='integer') \n",
    "dt6.leaves=pd.to_numeric(dt6.leaves,errors='coerce',downcast='integer') \n",
    "dt6.leaves_missing=pd.to_numeric(dt6.leaves_missing,errors='coerce',downcast='integer') \n",
    "dt6.leaf_area=pd.to_numeric(dt6.leaf_area,errors='coerce') \n",
    "dt6.num_samaras=pd.to_numeric(dt6.num_samaras,errors='coerce',downcast='integer') \n",
    "      \n",
    "\n",
    "infile7  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/53adcdd59f172b36e5d805789abd53b3\".strip() \n",
    "infile7  = infile7.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt7 =pd.read_csv(infile7 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"year\",     \n",
    "                    \"tree\",     \n",
    "                    \"branch\",     \n",
    "                    \"num_filled\",     \n",
    "                    \"num_empty\",     \n",
    "                    \"num_grub\",     \n",
    "                    \"num_wrinkle\",     \n",
    "                    \"num_small\",     \n",
    "                    \"num_moldy\",     \n",
    "                    \"num_exit\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'year',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'year':[\n",
    "                          'NA',],\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'branch':[\n",
    "                          'NA',],\n",
    "                  'num_filled':[\n",
    "                          'NA',],\n",
    "                  'num_empty':[\n",
    "                          'NA',],\n",
    "                  'num_grub':[\n",
    "                          'NA',],\n",
    "                  'num_wrinkle':[\n",
    "                          'NA',],\n",
    "                  'num_small':[\n",
    "                          'NA',],\n",
    "                  'num_moldy':[\n",
    "                          'NA',],\n",
    "                  'num_exit':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt7=dt7.assign(year_datetime=pd.to_datetime(dt7.year,errors='coerce'))  \n",
    "dt7.tree=dt7.tree.astype('category')  \n",
    "dt7.branch=dt7.branch.astype('category') \n",
    "dt7.num_filled=pd.to_numeric(dt7.num_filled,errors='coerce',downcast='integer') \n",
    "dt7.num_empty=pd.to_numeric(dt7.num_empty,errors='coerce',downcast='integer') \n",
    "dt7.num_grub=pd.to_numeric(dt7.num_grub,errors='coerce',downcast='integer') \n",
    "dt7.num_wrinkle=pd.to_numeric(dt7.num_wrinkle,errors='coerce',downcast='integer') \n",
    "dt7.num_small=pd.to_numeric(dt7.num_small,errors='coerce',downcast='integer') \n",
    "dt7.num_moldy=pd.to_numeric(dt7.num_moldy,errors='coerce',downcast='integer') \n",
    "dt7.num_exit=pd.to_numeric(dt7.num_exit,errors='coerce',downcast='integer') \n",
    "      \n",
    "infile8  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/a7652807020c976092ca8f762d1a9b97\".strip() \n",
    "infile8  = infile8.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt8 =pd.read_csv(infile8 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"year\",     \n",
    "                    \"tree\",     \n",
    "                    \"branch\",     \n",
    "                    \"treatment\",     \n",
    "                    \"num_filled\",     \n",
    "                    \"num_empty\",     \n",
    "                    \"num_grub\",     \n",
    "                    \"num_wrinkle\",     \n",
    "                    \"num_small\",     \n",
    "                    \"num_moldy\",     \n",
    "                    \"num_exit\",     \n",
    "                    \"num_missing\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'year',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'year':[\n",
    "                          'NA',],\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'branch':[\n",
    "                          'NA',],\n",
    "                  'treatment':[\n",
    "                          'NA',],\n",
    "                  'num_filled':[\n",
    "                          'NA',],\n",
    "                  'num_empty':[\n",
    "                          'NA',],\n",
    "                  'num_grub':[\n",
    "                          'NA',],\n",
    "                  'num_wrinkle':[\n",
    "                          'NA',],\n",
    "                  'num_small':[\n",
    "                          'NA',],\n",
    "                  'num_moldy':[\n",
    "                          'NA',],\n",
    "                  'num_exit':[\n",
    "                          'NA',],\n",
    "                  'num_missing':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt8=dt8.assign(year_datetime=pd.to_datetime(dt8.year,errors='coerce'))  \n",
    "dt8.tree=dt8.tree.astype('category')  \n",
    "dt8.branch=dt8.branch.astype('category')  \n",
    "dt8.treatment=dt8.treatment.astype('category') \n",
    "dt8.num_filled=pd.to_numeric(dt8.num_filled,errors='coerce',downcast='integer') \n",
    "dt8.num_empty=pd.to_numeric(dt8.num_empty,errors='coerce',downcast='integer') \n",
    "dt8.num_grub=pd.to_numeric(dt8.num_grub,errors='coerce',downcast='integer') \n",
    "dt8.num_wrinkle=pd.to_numeric(dt8.num_wrinkle,errors='coerce',downcast='integer') \n",
    "dt8.num_small=pd.to_numeric(dt8.num_small,errors='coerce',downcast='integer') \n",
    "dt8.num_moldy=pd.to_numeric(dt8.num_moldy,errors='coerce',downcast='integer') \n",
    "dt8.num_exit=pd.to_numeric(dt8.num_exit,errors='coerce',downcast='integer') \n",
    "dt8.num_missing=pd.to_numeric(dt8.num_missing,errors='coerce',downcast='integer') \n",
    "      \n",
    "\n",
    "infile9  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/420b180629ecc044e44f03edcd687bcb\".strip() \n",
    "infile9  = infile9.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt9 =pd.read_csv(infile9 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"tree\",     \n",
    "                    \"date\",     \n",
    "                    \"ec_count\",     \n",
    "                    \"jr_count\",     \n",
    "                    \"total_count\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'date',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'date':[\n",
    "                          'NA',],\n",
    "                  'ec_count':[\n",
    "                          'NA',],\n",
    "                  'jr_count':[\n",
    "                          'NA',],\n",
    "                  'total_count':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata  \n",
    "dt9.tree=dt9.tree.astype('category') \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt9=dt9.assign(date_datetime=pd.to_datetime(dt9.date,errors='coerce')) \n",
    "dt9.ec_count=pd.to_numeric(dt9.ec_count,errors='coerce',downcast='integer') \n",
    "dt9.jr_count=pd.to_numeric(dt9.jr_count,errors='coerce',downcast='integer') \n",
    "dt9.total_count=pd.to_numeric(dt9.total_count,errors='coerce',downcast='integer') \n",
    "      \n",
    "\n",
    "infile10  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/8dd0ed00b10ed71a56ab6d35b5b434de\".strip() \n",
    "infile10  = infile10.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt10 =pd.read_csv(infile10 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"year\",     \n",
    "                    \"tree\",     \n",
    "                    \"branch\",     \n",
    "                    \"treatment\",     \n",
    "                    \"num_flowering\",     \n",
    "                    \"num_notflowering\",     \n",
    "                    \"num_buds_w_samaras\",     \n",
    "                    \"num_samaras\",     \n",
    "                    \"num_petioles\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'year',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'year':[\n",
    "                          'NA',],\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'branch':[\n",
    "                          'NA',],\n",
    "                  'treatment':[\n",
    "                          'NA',],\n",
    "                  'num_flowering':[\n",
    "                          'NA',],\n",
    "                  'num_notflowering':[\n",
    "                          'NA',],\n",
    "                  'num_buds_w_samaras':[\n",
    "                          'NA',],\n",
    "                  'num_samaras':[\n",
    "                          'NA',],\n",
    "                  'num_petioles':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt10=dt10.assign(year_datetime=pd.to_datetime(dt10.year,errors='coerce'))  \n",
    "dt10.tree=dt10.tree.astype('category')  \n",
    "dt10.branch=dt10.branch.astype('category')  \n",
    "dt10.treatment=dt10.treatment.astype('category') \n",
    "dt10.num_flowering=pd.to_numeric(dt10.num_flowering,errors='coerce',downcast='integer') \n",
    "dt10.num_notflowering=pd.to_numeric(dt10.num_notflowering,errors='coerce',downcast='integer') \n",
    "dt10.num_buds_w_samaras=pd.to_numeric(dt10.num_buds_w_samaras,errors='coerce',downcast='integer') \n",
    "dt10.num_samaras=pd.to_numeric(dt10.num_samaras,errors='coerce',downcast='integer') \n",
    "dt10.num_petioles=pd.to_numeric(dt10.num_petioles,errors='coerce',downcast='integer') \n",
    "      \n",
    "                \n",
    "\n",
    "infile11  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/733485773d21cc6404b640de62c34e69\".strip() \n",
    "infile11  = infile11.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt11 =pd.read_csv(infile11 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"tree\",     \n",
    "                    \"branch\",     \n",
    "                    \"treatment\",     \n",
    "                    \"growth_year\",     \n",
    "                    \"internode_length\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'growth_year',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'branch':[\n",
    "                          'NA',],\n",
    "                  'treatment':[\n",
    "                          'NA',],\n",
    "                  'growth_year':[\n",
    "                          'NA',],\n",
    "                  'internode_length':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata  \n",
    "dt11.tree=dt11.tree.astype('category')  \n",
    "dt11.branch=dt11.branch.astype('category')  \n",
    "dt11.treatment=dt11.treatment.astype('category') \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt11=dt11.assign(growth_year_datetime=pd.to_datetime(dt11.growth_year,errors='coerce')) \n",
    "dt11.internode_length=pd.to_numeric(dt11.internode_length,errors='coerce') \n",
    "      \n",
    "            \n",
    "\n",
    "infile12  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/deac87be90dc1f4f8ad11e01e0cceca4\".strip() \n",
    "infile12  = infile12.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt12 =pd.read_csv(infile12 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"year\",     \n",
    "                    \"tree\",     \n",
    "                    \"branch\",     \n",
    "                    \"treatment\",     \n",
    "                    \"num_flowering\",     \n",
    "                    \"num_notflowering\",     \n",
    "                    \"num_buds_w_samaras\",     \n",
    "                    \"num_samaras\",     \n",
    "                    \"num_petioles\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'year',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'year':[\n",
    "                          'NA',],\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'branch':[\n",
    "                          'NA',],\n",
    "                  'treatment':[\n",
    "                          'NA',],\n",
    "                  'num_flowering':[\n",
    "                          'NA',],\n",
    "                  'num_notflowering':[\n",
    "                          'NA',],\n",
    "                  'num_buds_w_samaras':[\n",
    "                          'NA',],\n",
    "                  'num_samaras':[\n",
    "                          'NA',],\n",
    "                  'num_petioles':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt12=dt12.assign(year_datetime=pd.to_datetime(dt12.year,errors='coerce'))  \n",
    "dt12.tree=dt12.tree.astype('category')  \n",
    "dt12.branch=dt12.branch.astype('category')  \n",
    "dt12.treatment=dt12.treatment.astype('category') \n",
    "dt12.num_flowering=pd.to_numeric(dt12.num_flowering,errors='coerce',downcast='integer') \n",
    "dt12.num_notflowering=pd.to_numeric(dt12.num_notflowering,errors='coerce',downcast='integer') \n",
    "dt12.num_buds_w_samaras=pd.to_numeric(dt12.num_buds_w_samaras,errors='coerce',downcast='integer') \n",
    "dt12.num_samaras=pd.to_numeric(dt12.num_samaras,errors='coerce',downcast='integer') \n",
    "dt12.num_petioles=pd.to_numeric(dt12.num_petioles,errors='coerce',downcast='integer') \n",
    "      \n",
    "           \n",
    "\n",
    "infile13  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/e8f6a405cd20955005b066b524ed09c3\".strip() \n",
    "infile13  = infile13.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt13 =pd.read_csv(infile13 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"tree\",     \n",
    "                    \"branch\",     \n",
    "                    \"treatment\",     \n",
    "                    \"growth_year\",     \n",
    "                    \"internode_length\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'growth_year',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'branch':[\n",
    "                          'NA',],\n",
    "                  'treatment':[\n",
    "                          'NA',],\n",
    "                  'growth_year':[\n",
    "                          'NA',],\n",
    "                  'internode_length':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata  \n",
    "dt13.tree=dt13.tree.astype('category')  \n",
    "dt13.branch=dt13.branch.astype('category')  \n",
    "dt13.treatment=dt13.treatment.astype('category') \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt13=dt13.assign(growth_year_datetime=pd.to_datetime(dt13.growth_year,errors='coerce')) \n",
    "dt13.internode_length=pd.to_numeric(dt13.internode_length,errors='coerce') \n",
    "      \n",
    "             \n",
    "\n",
    "infile14  =\"https://pasta.lternet.edu/package/data/eml/knb-lter-hfr/285/3/bd5c44a085ab8b90ce758e1d1f1419e2\".strip() \n",
    "infile14  = infile14.replace(\"https://\",\"http://\")\n",
    "                 \n",
    "dt14 =pd.read_csv(infile14 \n",
    "          ,skiprows=1\n",
    "            ,sep=\",\"  \n",
    "           , names=[\n",
    "                    \"year\",     \n",
    "                    \"tree\",     \n",
    "                    \"branch\",     \n",
    "                    \"num_flowering\",     \n",
    "                    \"num_notflowering\",     \n",
    "                    \"num_buds_w_samaras\",     \n",
    "                    \"num_samaras\",     \n",
    "                    \"num_petioles\"    ]\n",
    "          ,parse_dates=[\n",
    "                        'year',\n",
    "                ] \n",
    "            ,na_values={\n",
    "                  'year':[\n",
    "                          'NA',],\n",
    "                  'tree':[\n",
    "                          'NA',],\n",
    "                  'branch':[\n",
    "                          'NA',],\n",
    "                  'num_flowering':[\n",
    "                          'NA',],\n",
    "                  'num_notflowering':[\n",
    "                          'NA',],\n",
    "                  'num_buds_w_samaras':[\n",
    "                          'NA',],\n",
    "                  'num_samaras':[\n",
    "                          'NA',],\n",
    "                  'num_petioles':[\n",
    "                          'NA',],} \n",
    "            \n",
    "    )\n",
    "# Coerce the data into the types specified in the metadata \n",
    "# Since date conversions are tricky, the coerced dates will go into a new column with _datetime appended\n",
    "# This new column is added to the dataframe but does not show up in automated summaries below. \n",
    "dt14=dt14.assign(year_datetime=pd.to_datetime(dt14.year,errors='coerce'))  \n",
    "dt14.tree=dt14.tree.astype('category')  \n",
    "dt14.branch=dt14.branch.astype('category') \n",
    "dt14.num_flowering=pd.to_numeric(dt14.num_flowering,errors='coerce',downcast='integer') \n",
    "dt14.num_notflowering=pd.to_numeric(dt14.num_notflowering,errors='coerce',downcast='integer') \n",
    "dt14.num_buds_w_samaras=pd.to_numeric(dt14.num_buds_w_samaras,errors='coerce',downcast='integer') \n",
    "dt14.num_samaras=pd.to_numeric(dt14.num_samaras,errors='coerce',downcast='integer') \n",
    "dt14.num_petioles=pd.to_numeric(dt14.num_petioles,errors='coerce',downcast='integer') \n",
    "      \n",
    "\n",
    "\n",
    "if not os.path.exists('../data/rapp2016/raw'):\n",
    "    os.makedirs('../data/rapp2016/raw')\n",
    "\n",
    "dt_nums = [str(x) for x in list(range(1,15))]\n",
    "\n",
    "for dt_num in dt_nums:\n",
    "    globals()['dt' + dt_num].to_pickle('../data/rapp2016/' + 'dt' + dt_num.zfill(2))\n",
    "    del globals()['dt' + dt_num]\n",
    "    \n",
    "    \n",
    "# Download raw data and save as csv\n",
    "for dt_num in dt_nums:\n",
    "    raw_data = requests.get(globals()['infile' + dt_num])\n",
    "    with open('../data/rapp2016/raw/rapp2016_raw' + dt_num.zfill(2) + '.csv', 'wb+') as data_file:\n",
    "        data_file.write(raw_data.content)\n",
    "\n",
    "# Download metadata and save\n",
    "metadata_url = 'https://pasta.lternet.edu/package/metadata/eml/knb-lter-hfr/285/3'\n",
    "metadata_xml = requests.get(metadata_url)\n",
    "\n",
    "with open('../data/rapp2016/raw/rapp2016_metadata.xml', 'w+') as metadata_file:\n",
    "     metadata_file.write(metadata_xml.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads 15-min metric weather files from Fisher Meteorological Station at Harvard Forest since 2005\n",
    "\n",
    "## Data website ##\n",
    "# https://harvardforest1.fas.harvard.edu/exist/apps/datasets/showData.html?id=HF001\n",
    "\n",
    "## Citation ##\n",
    "# Boose E. 2018. Fisher Meteorological Station at Harvard Forest since 2001. Harvard Forest Data Archive: HF001.\n",
    "\n",
    "\n",
    "if not os.path.exists(\"../data/HF_weather/raw\"):\n",
    "    os.makedirs(\"../data/HF_weather/raw\")\n",
    "    \n",
    "HF_weather_url = 'https://harvardforest.fas.harvard.edu/data/p00/hf001/hf001-10-15min-m.csv'\n",
    "HF_weather_csv = requests.get(HF_weather_url)\n",
    "\n",
    "with open('../data/HF_weather/raw/hf001-08-hourly-m.csv', 'wb+') as raw_data:\n",
    "    raw_data.write(HF_weather_csv.content)\n",
    "        \n",
    "# Download metadata and save\n",
    "metadata_url = 'http://harvardforest.fas.harvard.edu/data/eml/hf001.xml'\n",
    "metadata_xml = requests.get(metadata_url)\n",
    "\n",
    "with open('../data/HF_weather/raw/HF_metadata.xml', 'w+') as metadata_file:\n",
    "     metadata_file.write(metadata_xml.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
